INFO 09-15 12:12:38 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
All deep_gemm operations loaded successfully!
INFO 09-15 12:12:44 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
INFO 09-15 12:12:46 [cache_tensor_manager.py:17] USE_GPU_TENSOR_CACHE is On
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
All deep_gemm operations loaded successfully!
INFO 09-15 12:12:53 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
INFO 09-15 12:12:54 [__init__.py:241] Automatically detected platform cuda.
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 0 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 1 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 2 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 3 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 4 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 6 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 5 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[Gloo] Rank 7 is connected to 7 peer ranks. Expected number of connected peer ranks is : 7
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
[40]
INFO 09-15 12:13:34 [communication_op.py:75] Enable Custom ALLReduce. You can disable it by settting --disable_custom_allreduce.
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [__init__.py:45] select fp8w8a8-b128 quant way: deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:13:34 [basemodel.py:141] Initial quantization. The default quantization method is deepgemm-fp8w8a8-b128
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [mem_manager.py:76] 44.0347900390625 GB space is available after load the model weight
INFO 09-15 12:14:55 [mem_manager.py:76] 0.0670166015625 MB is the size of one token kv cache
INFO 09-15 12:14:55 [mem_manager.py:76] 672842 is the profiled max_total_token_num with the mem_fraction 0.9
INFO 09-15 12:14:55 [mem_manager.py:76] 
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_7
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_2
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_3
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_1
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_4
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_0
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_6
INFO 09-15 12:14:55 [shared_arr.py:17] create shm None_mem_manger_can_use_token_num_5
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for rotary_emb_fwd:v1 - frozendict.frozendict({'Q_HEAD_NUM': 16, 'K_HEAD_NUM': 1, 'HEAD_DIM': 64, 'dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 2304, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_align_fused:v1 - frozendict.frozendict({'topk': 9})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 512, 'K': 7168, 'topk_num': 9, 'expert_num': 257, 'mul_routed_weight': False, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for silu_and_mul_fwd:v1 - frozendict.frozendict({'N': 256, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for grouped_matmul:v1 - frozendict.frozendict({'N': 7168, 'K': 256, 'topk_num': 1, 'expert_num': 257, 'mul_routed_weight': True, 'use_fp8_w8a8': True, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:14:57 [autotuner.py:218] Loading cached configs for moe_sum_reduce:v1 - frozendict.frozendict({'topk_num': 9, 'hidden_dim': 7168, 'out_dtype': 'torch.bfloat16'})
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cuda_graph.py:45] cuda graph batch_sizes: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 48]
INFO 09-15 12:15:00 [cuda_graph.py:187] Begin capture cudagraph, use the --disable_cudagraph to disable it.
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148976 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148980 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148978 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148977 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148974 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148973 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148979 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:00 [cache_tensor_manager.py:75] pid 1148975 cuda graph alloc graph out mem (48, 129280) torch.float32 6205440 6205440
INFO 09-15 12:15:00 [cache_tensor_manager.py:77] cuda graph managed_total_tensor_bytes: 24821760
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [cuda_graph.py:236] Capture cudagraph success, batch_size <=48 and max_len_in_batch <= 16384 will infer with cudagraph.
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:684] begin check max_len infer
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
INFO 09-15 12:15:17 [basemodel.py:714] check max_len 1024 infer ok
Testing batch size 40
prefill time cost: 408.5721969604492, prefill throughput: 25062.261059135133 tokens/s
i: 0, step cost time: 20.673036575317383 ms, throughput: 1934.5528342788616 tokens/s
i: 9, step cost time: 21.63410186767578 ms, throughput: 1848.6271830753126 tokens/s
prefill time cost: 389.06240463256836, prefill throughput: 26319.346466348055 tokens/s
Profile Prefill
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                   lightllm::inplace_fused_experts_impl        10.56%      33.914ms        17.38%      55.776ms     961.660us     166.313ms        42.91%     369.578ms       6.372ms            58  
                                    Command Buffer Full        23.11%      74.170ms        23.16%      74.336ms     235.241us     204.563ms        52.78%     204.563ms     647.352us           316  
                                       cuLaunchKernelEx         1.93%       6.187ms        17.25%      55.385ms      43.507us       2.124ms         0.55%     198.584ms     155.997us          1273  
                                  grouped_matmul_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     142.824ms        36.85%     142.824ms       1.231ms           116  
                                     record_param_comms         2.02%       6.500ms         4.26%      13.688ms     110.386us      87.533ms        22.59%      87.589ms     706.362us           124  
                                       c10d::allreduce_         0.86%       2.764ms         4.26%      13.685ms     111.256us       0.000us         0.00%      87.486ms     711.269us           123  
ncclDevKernel_AllReduce_Sum_bf16_RING_LL(ncclDevKern...         0.00%       0.000us         0.00%       0.000us       0.000us      87.486ms        22.57%      87.486ms     711.269us           123  
                                        nccl:all_reduce         0.00%       0.000us         0.00%       0.000us       0.000us      87.486ms        22.57%      87.486ms     711.269us           123  
                                 deep_gemm::fp8_gemm_nt         1.74%       5.585ms         6.07%      19.473ms      62.613us      41.756ms        10.77%      48.615ms     156.317us           311  
              sgl_kernel::sgl_per_token_group_quant_fp8         0.33%       1.050ms         4.28%      13.728ms      32.150us      42.089ms        10.86%      42.722ms     100.052us           427  
void per_token_group_quant_8bit_kernel<__nv_bfloat16...         0.00%       0.000us         0.00%       0.000us       0.000us      28.759ms         7.42%      28.759ms      92.473us           311  
                                 _moe_sum_reduce_kernel         0.00%       0.000us         0.00%       0.000us       0.000us      19.630ms         5.07%      19.630ms     338.441us            58  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 7168u, 2...         0.00%       0.000us         0.00%       0.000us       0.000us      15.603ms         4.03%      15.603ms     255.783us            61  
                                             aten::add_         0.38%       1.225ms         0.65%       2.100ms      13.047us      12.425ms         3.21%      14.459ms      89.810us           161  
void per_token_group_quant_8bit_kernel<__nv_bfloat16...         0.00%       0.000us         0.00%       0.000us       0.000us      13.330ms         3.44%      13.330ms     114.915us           116  
void at::native::vectorized_elementwise_kernel<8, at...         0.00%       0.000us         0.00%       0.000us       0.000us      12.425ms         3.21%      12.425ms     101.841us           122  
                                    _rms_norm_fwd_fused         0.00%       0.000us         0.00%       0.000us       0.000us      12.285ms         3.17%      12.285ms      50.143us           245  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 1536u, 7...         0.00%       0.000us         0.00%       0.000us       0.000us      10.888ms         2.81%      10.888ms     178.498us            61  
                                              aten::cat         0.54%       1.734ms         1.69%       5.431ms      30.686us       7.064ms         1.82%       9.153ms      51.714us           177  
                                        sgl_kernel::fwd         0.39%       1.253ms         1.57%       5.026ms      82.388us       4.148ms         1.07%       6.867ms     112.571us            61  
                                       cudaLaunchKernel         1.73%       5.569ms         9.52%      30.556ms      25.108us       0.000us         0.00%       6.834ms       5.615us          1217  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       6.711ms         1.73%       6.711ms     110.022us            61  
                                    grouped_topk_kernel         0.00%       0.000us         0.00%       0.000us       0.000us       5.474ms         1.41%       5.474ms      94.380us            58  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 3072u, 1...         0.00%       0.000us         0.00%       0.000us       0.000us       5.448ms         1.41%       5.448ms      89.320us            61  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 576u, 71...         0.00%       0.000us         0.00%       0.000us       0.000us       4.421ms         1.14%       4.421ms      72.482us            61  
void cutlass::device_kernel<flash::enable_sm90_or_la...         0.00%       0.000us         0.00%       0.000us       0.000us       3.985ms         1.03%       3.985ms      65.324us            61  
                    cudaThreadExchangeStreamCaptureMode         0.03%      98.154us         0.03%      98.154us       0.203us       3.706ms         0.96%       3.706ms       7.658us           484  
                                            aten::copy_         0.51%       1.629ms         4.06%      13.044ms      54.578us       2.435ms         0.63%       3.156ms      13.206us           239  
                                               aten::mm         0.75%       2.397ms         0.85%       2.743ms      46.494us       3.118ms         0.80%       3.118ms      52.851us            59  
                    nvjet_tst_128x160_64x5_2x1_v_bz_TNT         0.00%       0.000us         0.00%       0.000us       0.000us       3.053ms         0.79%       3.053ms      52.637us            58  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 4096u, 5...         0.00%       0.000us         0.00%       0.000us       0.000us       3.048ms         0.79%       3.048ms      49.971us            61  
                                            aten::clone         0.10%     309.490us         2.82%       9.056ms      74.226us       0.000us         0.00%       2.905ms      23.815us           122  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.244ms         0.58%       2.244ms      17.259us           130  
                              _silu_and_mul_kernel_fast         0.00%       0.000us         0.00%       0.000us       0.000us       2.021ms         0.52%       2.021ms      33.124us            61  
                                aten::repeat_interleave         0.08%     253.022us         0.80%       2.565ms      42.057us       0.000us         0.00%       1.946ms      31.900us            61  
                                         _rotary_kernel         0.00%       0.000us         0.00%       0.000us       0.000us       1.926ms         0.50%       1.926ms      31.578us            61  
                                 moe_align_fused_kernel         0.00%       0.000us         0.00%       0.000us       0.000us       1.798ms         0.46%       1.798ms      30.992us            58  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 4608u, 7...         0.00%       0.000us         0.00%       0.000us       0.000us       1.522ms         0.39%       1.522ms     507.415us             3  
                                    cudaLaunchKernelExC         0.10%     324.996us         0.15%     481.163us       7.888us       0.000us         0.00%       1.359ms      22.282us            61  
                                         cudaEventQuery         0.27%     861.532us         0.27%     861.788us       1.814us     982.752us         0.25%     982.752us       2.069us           475  
                                       aten::contiguous         0.04%     132.067us         2.29%       7.336ms     120.257us       0.000us         0.00%     959.489us      15.729us            61  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 7168u, 2...         0.00%       0.000us         0.00%       0.000us       0.000us     824.451us         0.21%     824.451us     274.817us             3  
                          _fwd_kernel_destindex_copy_kv         0.00%       0.000us         0.00%       0.000us       0.000us     483.934us         0.12%     483.934us       7.933us            61  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     183.007us         0.05%     183.007us       3.155us            58  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     169.250us         0.04%     169.250us       2.918us            58  
flash::prepare_varlen_num_blocks_kernel(int, int, in...         0.00%       0.000us         0.00%       0.000us       0.000us     163.744us         0.04%     163.744us       2.684us            61  
                                            aten::fill_         0.14%     464.335us         0.30%     955.626us       8.099us     144.733us         0.04%     144.733us       1.227us           118  
                                      moe_align2_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     139.708us         0.04%     139.708us       2.409us            58  
                                           aten::arange         0.14%     454.694us         0.54%       1.722ms      14.841us      67.360us         0.02%     134.720us       1.161us           116  
                                           aten::repeat         0.15%     466.576us         0.56%       1.809ms      31.181us       0.000us         0.00%     115.938us       1.999us            58  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     115.938us         0.03%     115.938us       1.999us            58  
                                       c10d::allgather_         0.01%      25.975us         0.87%       2.793ms       2.793ms       0.000us         0.00%     102.850us     102.850us             1  
                                             aten::mul_         0.19%     595.519us         0.27%     871.553us      15.027us      87.553us         0.02%      87.553us       1.510us            58  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      87.553us         0.02%      87.553us       1.510us            58  
                                        nccl:all_gather         0.00%       0.000us         0.00%       0.000us       0.000us      86.784us         0.02%      86.784us      86.784us             1  
                                            aten::zeros         0.04%     138.552us         0.28%     898.740us      15.233us       0.000us         0.00%      76.350us       1.294us            59  
                                            aten::zero_         0.03%     100.511us         0.18%     570.009us       9.661us       0.000us         0.00%      76.350us       1.294us            59  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      76.350us         0.02%      76.350us       1.316us            58  
                                       embedding_kernel         0.00%       0.000us         0.00%       0.000us       0.000us      68.416us         0.02%      68.416us      68.416us             1  
                                             aten::full         0.04%     133.617us         0.25%     787.201us      13.572us       0.000us         0.00%      68.383us       1.179us            58  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      68.383us         0.02%      68.383us       1.179us            58  
                                            aten::slice         0.97%       3.100ms         1.21%       3.880ms       1.751us       0.000us         0.00%      68.288us       0.031us          2216  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us      67.360us         0.02%      67.360us       1.161us            58  
                    nvjet_tst_128x40_64x10_2x1_v_bz_TNT         0.00%       0.000us         0.00%       0.000us       0.000us      65.280us         0.02%      65.280us      65.280us             1  
                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      48.513us         0.01%      48.513us       1.183us            41  
ncclDevKernel_AllGather_RING_LL(ncclDevKernelArgsSto...         0.00%       0.000us         0.00%       0.000us       0.000us      47.232us         0.01%      47.232us      47.232us             1  
                                               aten::to         0.01%      29.307us         0.54%       1.726ms     172.586us       0.000us         0.00%      17.920us       1.792us            10  
                                         aten::_to_copy         0.01%      24.961us         0.53%       1.697ms     188.506us       0.000us         0.00%      17.920us       1.991us             9  
                                     aten::index_select         0.01%      21.181us         0.02%      70.143us      35.072us       0.000us         0.00%      15.712us       7.856us             2  
                                           aten::gather         0.00%      15.978us         0.01%      33.644us      16.822us      15.712us         0.00%      15.712us       7.856us             2  
void at::native::vectorized_gather_kernel<16, int>(c...         0.00%       0.000us         0.00%       0.000us       0.000us      15.712us         0.00%      15.712us       7.856us             2  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      12.929us         0.00%      12.929us      12.929us             1  
                         Memcpy HtoD (Pinned -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       7.232us         0.00%       7.232us       1.808us             4  
                                           aten::cumsum         0.01%      19.057us         0.02%      60.731us      60.731us       4.032us         0.00%       5.632us       5.632us             1  
                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       4.928us         0.00%       4.928us       2.464us             2  
                                              aten::sub         0.04%     132.308us         0.05%     158.419us       1.886us       4.223us         0.00%       4.223us       0.050us            84  
                                Activity Buffer Request         0.48%       1.526ms         0.48%       1.526ms       1.526ms       4.160us         0.00%       4.160us       4.160us             1  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       2.911us         0.00%       2.911us       1.456us             2  
void at_cuda_detail::cub::DeviceScanKernel<at_cuda_d...         0.00%       0.000us         0.00%       0.000us       0.000us       2.560us         0.00%       2.560us       2.560us             1  
                                            aten::index         0.00%      15.763us         0.01%      23.989us      23.989us       2.464us         0.00%       2.464us       2.464us             1  
void at::native::vectorized_gather_kernel<16, long>(...         0.00%       0.000us         0.00%       0.000us       0.000us       2.464us         0.00%       2.464us       2.464us             1  
                                _gen_cumsum_pad0_kernel         0.00%       0.000us         0.00%       0.000us       0.000us       2.432us         0.00%       2.432us       2.432us             1  
                                  _gen_prefill_position         0.00%       0.000us         0.00%       0.000us       0.000us       1.856us         0.00%       1.856us       1.856us             1  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.600us         0.00%       1.600us       1.600us             1  
void at_cuda_detail::cub::DeviceScanInitKernel<at_cu...         0.00%       0.000us         0.00%       0.000us       0.000us       1.472us         0.00%       1.472us       1.472us             1  
void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.312us         0.00%       1.312us       1.312us             1  
                                            aten::empty         1.48%       4.740ms         1.48%       4.740ms       3.580us       0.000us         0.00%       0.000us       0.000us          1324  
                                    aten::empty_strided         0.01%      39.272us         0.01%      39.272us       3.927us       0.000us         0.00%       0.000us       0.000us            10  
                                        cudaMemcpyAsync         0.08%     264.448us         0.08%     264.448us       5.627us       0.000us         0.00%       0.000us       0.000us            47  
                                           aten::select         0.15%     471.700us         0.17%     546.631us       1.885us       0.000us         0.00%       0.000us       0.000us           290  
                                       aten::as_strided         0.59%       1.901ms         0.59%       1.906ms       0.398us       0.000us         0.00%       0.000us       0.000us          4789  
                                              aten::add         0.02%      57.219us         0.02%      66.978us       1.634us       0.000us         0.00%       0.000us       0.000us            41  
                                             aten::item         0.09%     292.119us         0.12%     381.293us       1.188us       0.000us         0.00%       0.000us       0.000us           321  
                              aten::_local_scalar_dense         0.03%      89.174us         0.03%      89.174us       0.278us       0.000us         0.00%       0.000us       0.000us           321  
                                              aten::max         0.00%       8.933us         0.00%      12.288us       6.144us       0.000us         0.00%       0.000us       0.000us             2  
                                           aten::detach         0.00%       2.877us         0.00%       5.661us       5.661us       0.000us         0.00%       0.000us       0.000us             1  
                                                 detach         0.00%       2.784us         0.00%       2.784us       2.784us       0.000us         0.00%       0.000us       0.000us             1  
                                     aten::resolve_conj         0.00%       0.228us         0.00%       0.228us       0.228us       0.000us         0.00%       0.000us       0.000us             1  
                                      aten::resolve_neg         0.00%       0.156us         0.00%       0.156us       0.156us       0.000us         0.00%       0.000us       0.000us             1  
                                          aten::resize_         0.05%     174.554us         0.05%     174.554us       2.909us       0.000us         0.00%       0.000us       0.000us            60  
                                             aten::view         0.59%       1.880ms         0.59%       1.880ms       0.910us       0.000us         0.00%       0.000us       0.000us          2066  
                                           aten::expand         0.09%     300.759us         0.13%     413.733us       2.311us       0.000us         0.00%       0.000us       0.000us           179  
                                  cudaStreamIsCapturing         0.06%     186.858us         0.06%     186.858us       0.753us       0.000us         0.00%       0.000us       0.000us           248  
                                        nccl:all_reduce         0.00%       0.000us             0       9.048ms      73.562us       0.000us         0.00%       0.000us       0.000us           123  
                            cudaStreamGetCaptureInfo_v2         0.04%     128.311us         0.04%     128.311us       1.035us       0.000us         0.00%       0.000us       0.000us           124  
                                    cudaStreamWaitEvent         0.16%     502.947us         0.16%     502.947us       1.352us       0.000us         0.00%       0.000us       0.000us           372  
                                        cudaEventRecord         0.16%     500.413us         0.16%     500.413us       1.009us       0.000us         0.00%       0.000us       0.000us           496  
                                    cudaGetFuncBySymbol         0.02%      55.373us         0.02%      55.373us       0.447us       0.000us         0.00%       0.000us       0.000us           124  
                               cudaEventRecordWithFlags         0.07%     225.712us         0.07%     225.712us       1.820us       0.000us         0.00%       0.000us       0.000us           124  
                                          aten::permute         0.19%     611.817us         0.25%     787.310us       2.532us       0.000us         0.00%       0.000us       0.000us           311  
                                                aten::t         0.27%     865.742us         0.48%       1.530ms       2.456us       0.000us         0.00%       0.000us       0.000us           623  
                                        aten::transpose         0.14%     442.552us         0.21%     664.212us       1.066us       0.000us         0.00%       0.000us       0.000us           623  
                                        aten::unsqueeze         0.18%     584.188us         0.24%     784.465us       2.109us       0.000us         0.00%       0.000us       0.000us           372  
                                          aten::squeeze         0.20%     626.948us         0.23%     753.014us       2.421us       0.000us         0.00%       0.000us       0.000us           311  
                                 aten::split_with_sizes         0.19%     597.909us         0.23%     742.854us       4.059us       0.000us         0.00%       0.000us       0.000us           183  
                                       aten::empty_like         0.06%     187.031us         0.29%     940.099us       7.643us       0.000us         0.00%       0.000us       0.000us           123  
                                          aten::reshape         0.07%     218.490us         0.10%     318.607us       2.590us       0.000us         0.00%       0.000us       0.000us           123  
                                          aten::flatten         0.03%      93.499us         0.05%     155.194us       2.544us       0.000us         0.00%       0.000us       0.000us            61  
                                cudaGetDriverEntryPoint         0.03%      88.892us         0.03%      88.892us       0.291us       0.000us         0.00%       0.000us       0.000us           305  
                                   cudaFuncSetAttribute         0.02%      62.205us         0.02%      62.205us       1.020us       0.000us         0.00%       0.000us       0.000us            61  
                                            aten::alias         0.02%      71.684us         0.02%      71.684us       1.236us       0.000us         0.00%       0.000us       0.000us            58  
                                           aten::unfold         0.04%     114.582us         0.06%     182.945us       1.577us       0.000us         0.00%       0.000us       0.000us           116  
                                        aten::expand_as         0.01%      34.824us         0.04%     114.824us       1.980us       0.000us         0.00%       0.000us       0.000us            58  
                                    cudaPeekAtLastError         0.00%       0.293us         0.00%       0.293us       0.073us       0.000us         0.00%       0.000us       0.000us             4  
cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFla...         0.00%       2.561us         0.00%       2.561us       2.561us       0.000us         0.00%       0.000us       0.000us             1  
                                 cudaDeviceGetAttribute         0.00%       0.741us         0.00%       0.741us       0.741us       0.000us         0.00%       0.000us       0.000us             1  
                                     aten::is_same_size         0.00%       1.359us         0.00%       1.359us       0.170us       0.000us         0.00%       0.000us       0.000us             8  
                                        nccl:all_gather         0.00%       0.000us             0       2.739ms       2.739ms       0.000us         0.00%       0.000us       0.000us             1  
                                  cudaDeviceSynchronize        47.15%     151.352ms        47.24%     151.651ms     151.651ms       0.000us         0.00%       0.000us       0.000us             1  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 321.004ms
Self CUDA time total: 387.548ms

i: 0, step cost time: 22.615909576416016 ms, throughput: 1768.2749607394683 tokens/s
i: 100, step cost time: 23.273706436157227 ms, throughput: 1718.3080358057314 tokens/s
i: 200, step cost time: 24.602651596069336 ms, throughput: 1624.9591755692659 tokens/s
i: 300, step cost time: 23.3609676361084 ms, throughput: 1711.8909432268072 tokens/s
i: 400, step cost time: 23.371458053588867 ms, throughput: 1710.9831116912785 tokens/s
i: 500, step cost time: 23.408889770507812 ms, throughput: 1707.8654247467807 tokens/s
i: 600, step cost time: 23.839712142944336 ms, throughput: 1677.0507796881247 tokens/s
i: 700, step cost time: 23.3609676361084 ms, throughput: 1711.9084109670112 tokens/s
i: 800, step cost time: 23.50759506225586 ms, throughput: 1700.6635513071333 tokens/s
i: 900, step cost time: 23.508787155151367 ms, throughput: 1700.8704467806851 tokens/s
i: 1000, step cost time: 23.64659309387207 ms, throughput: 1691.2516129032258 tokens/s
i: 1100, step cost time: 23.80514144897461 ms, throughput: 1679.552312020102 tokens/s
i: 1200, step cost time: 23.88739585876465 ms, throughput: 1674.005308215761 tokens/s
i: 1300, step cost time: 23.8037109375 ms, throughput: 1680.056879061896 tokens/s
i: 1400, step cost time: 24.384737014770508 ms, throughput: 1639.9855328882416 tokens/s
i: 1500, step cost time: 24.158239364624023 ms, throughput: 1655.4393858662404 tokens/s
i: 1600, step cost time: 23.955345153808594 ms, throughput: 1668.8931552089448 tokens/s
i: 1700, step cost time: 24.214744567871094 ms, throughput: 1651.5608757284613 tokens/s
i: 1800, step cost time: 24.344921112060547 ms, throughput: 1642.667084418509 tokens/s
i: 1900, step cost time: 24.2922306060791 ms, throughput: 1646.3423154671952 tokens/s
i: 2000, step cost time: 24.553298950195312 ms, throughput: 1628.8242946738899 tokens/s
i: 2100, step cost time: 24.585723876953125 ms, throughput: 1626.6764916907443 tokens/s
i: 2200, step cost time: 24.370193481445312 ms, throughput: 1641.0763647745835 tokens/s
i: 2300, step cost time: 24.67513084411621 ms, throughput: 1620.282582452074 tokens/s
i: 2400, step cost time: 24.604082107543945 ms, throughput: 1625.4472174856612 tokens/s
i: 2500, step cost time: 24.692773818969727 ms, throughput: 1619.625628698582 tokens/s
i: 2600, step cost time: 24.37305450439453 ms, throughput: 1640.8837595970463 tokens/s
i: 2700, step cost time: 24.77741241455078 ms, throughput: 1614.1406016990734 tokens/s
i: 2800, step cost time: 25.55084228515625 ms, throughput: 1565.2724287207045 tokens/s
i: 2900, step cost time: 24.951696395874023 ms, throughput: 1602.8523659848477 tokens/s
i: 3000, step cost time: 24.950742721557617 ms, throughput: 1602.806427575138 tokens/s
i: 3100, step cost time: 25.226593017578125 ms, throughput: 1585.34362686271 tokens/s
i: 3200, step cost time: 27.708053588867188 ms, throughput: 1443.4000378546725 tokens/s
i: 3300, step cost time: 25.234460830688477 ms, throughput: 1584.2657626606483 tokens/s
i: 3400, step cost time: 25.22897720336914 ms, throughput: 1585.1189508890611 tokens/s
i: 3500, step cost time: 25.421619415283203 ms, throughput: 1572.977057726024 tokens/s
i: 3600, step cost time: 25.481700897216797 ms, throughput: 1569.4895973656637 tokens/s
i: 3700, step cost time: 25.429248809814453 ms, throughput: 1572.7411295992501 tokens/s
i: 3800, step cost time: 25.667905807495117 ms, throughput: 1558.1058164696267 tokens/s
i: 3900, step cost time: 25.589704513549805 ms, throughput: 1562.866538114002 tokens/s
i: 4000, step cost time: 25.51102638244629 ms, throughput: 1567.7150359288712 tokens/s
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
void sglang::cross_device_reduce_2stage<__nv_bfloat1...         0.00%       0.000us         0.00%       0.000us       0.000us      12.411ms        36.32%      12.411ms     100.901us           123  
                                  grouped_matmul_kernel         0.00%       0.000us         0.00%       0.000us       0.000us      10.897ms        31.89%      10.897ms      93.936us           116  
void cutlass::device_kernel<flash::enable_sm90_or_la...         0.00%       0.000us         0.00%       0.000us       0.000us       3.694ms        10.81%       3.694ms      60.552us            61  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 1536u, 7...         0.00%       0.000us         0.00%       0.000us       0.000us     647.302us         1.89%     647.302us      10.612us            61  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 576u, 71...         0.00%       0.000us         0.00%       0.000us       0.000us     624.706us         1.83%     624.706us      10.241us            61  
                                    _rms_norm_fwd_fused         0.00%       0.000us         0.00%       0.000us       0.000us     603.529us         1.77%     603.529us       2.463us           245  
void per_token_group_quant_8bit_kernel<__nv_bfloat16...         0.00%       0.000us         0.00%       0.000us       0.000us     589.456us         1.73%     589.456us       2.358us           250  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 7168u, 2...         0.00%       0.000us         0.00%       0.000us       0.000us     487.878us         1.43%     487.878us       7.998us            61  
                                    grouped_topk_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     330.339us         0.97%     330.339us       5.696us            58  
              nvjet_tst_64x16_64x16_2x4_v_bz_splitK_TNT         0.00%       0.000us         0.00%       0.000us       0.000us     318.211us         0.93%     318.211us       5.486us            58  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 3072u, 1...         0.00%       0.000us         0.00%       0.000us       0.000us     297.181us         0.87%     297.181us       4.872us            61  
void per_token_group_quant_8bit_kernel<__nv_bfloat16...         0.00%       0.000us         0.00%       0.000us       0.000us     256.607us         0.75%     256.607us       2.212us           116  
                     nvjet_tst_64x16_64x16_2x1_v_bz_NNT         0.00%       0.000us         0.00%       0.000us       0.000us     246.431us         0.72%     246.431us       4.040us            61  
void cutlass::device_kernel<flash::FlashAttnFwdCombi...         0.00%       0.000us         0.00%       0.000us       0.000us     243.558us         0.71%     243.558us       3.993us            61  
                     nvjet_tst_64x48_64x15_2x1_v_bz_NNT         0.00%       0.000us         0.00%       0.000us       0.000us     234.373us         0.69%     234.373us       3.842us            61  
void at::native::vectorized_elementwise_kernel<8, at...         0.00%       0.000us         0.00%       0.000us       0.000us     229.062us         0.67%     229.062us       1.878us           122  
                                 _moe_sum_reduce_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     213.663us         0.63%     213.663us       3.684us            58  
                                 moe_align_fused_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     198.112us         0.58%     198.112us       3.416us            58  
void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     193.537us         0.57%     193.537us       2.805us            69  
flash::prepare_varlen_num_blocks_kernel(int, int, in...         0.00%       0.000us         0.00%       0.000us       0.000us     148.805us         0.44%     148.805us       2.439us            61  
                              _silu_and_mul_kernel_fast         0.00%       0.000us         0.00%       0.000us       0.000us     122.690us         0.36%     122.690us       2.011us            61  
                                         _rotary_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     120.512us         0.35%     120.512us       1.976us            61  
                                      moe_align2_kernel         0.00%       0.000us         0.00%       0.000us       0.000us     112.832us         0.33%     112.832us       1.945us            58  
void cublasLt::splitKreduce_kernel<32, 16, int, floa...         0.00%       0.000us         0.00%       0.000us       0.000us     111.044us         0.32%     111.044us       1.915us            58  
                          _fwd_kernel_destindex_copy_kv         0.00%       0.000us         0.00%       0.000us       0.000us      81.534us         0.24%      81.534us       1.337us            61  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      80.898us         0.24%      80.898us       1.395us            58  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      77.982us         0.23%      77.982us       1.345us            58  
void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us      77.501us         0.23%      77.501us       1.336us            58  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us      70.237us         0.21%      70.237us       1.211us            58  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      65.120us         0.19%      65.120us       1.104us            59  
                     nvjet_tst_128x48_64x9_2x1_v_bz_TNT         0.00%       0.000us         0.00%       0.000us       0.000us      61.953us         0.18%      61.953us      61.953us             1  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      59.167us         0.17%      59.167us       1.020us            58  
void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us      56.417us         0.17%      56.417us       0.973us            58  
ncclDevKernel_AllGather_RING_LL(ncclDevKernelArgsSto...         0.00%       0.000us         0.00%       0.000us       0.000us      51.584us         0.15%      51.584us      51.584us             1  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 4608u, 7...         0.00%       0.000us         0.00%       0.000us       0.000us      41.472us         0.12%      41.472us      13.824us             3  
                                       embedding_kernel         0.00%       0.000us         0.00%       0.000us       0.000us      34.433us         0.10%      34.433us      34.433us             1  
void deep_gemm::sm90_fp8_gemm_1d2d_impl<0u, 7168u, 2...         0.00%       0.000us         0.00%       0.000us       0.000us      25.920us         0.08%      25.920us       8.640us             3  
                                            aten::copy_         0.21%      88.326us         5.25%       2.165ms      86.604us      21.824us         0.06%      21.824us       0.873us            25  
                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us      16.352us         0.05%      16.352us       1.090us            15  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us      16.321us         0.05%      16.321us      16.321us             1  
                                            aten::fill_         0.05%      19.842us         0.17%      68.616us      11.436us       4.224us         0.01%       4.224us       0.704us             6  
                                            aten::index         0.04%      15.994us         0.11%      45.311us      45.311us       2.752us         0.01%       4.192us       4.192us             1  
                                     aten::index_select         0.04%      16.486us         0.14%      57.118us      28.559us       0.000us         0.00%       3.168us       1.584us             2  
                                           aten::gather         0.03%      13.194us         0.06%      26.617us      13.309us       3.168us         0.01%       3.168us       1.584us             2  
void at::native::vectorized_gather_kernel<16, int>(c...         0.00%       0.000us         0.00%       0.000us       0.000us       3.168us         0.01%       3.168us       1.584us             2  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       3.104us         0.01%       3.104us       3.104us             1  
void at::native::vectorized_gather_kernel<16, long>(...         0.00%       0.000us         0.00%       0.000us       0.000us       2.752us         0.01%       2.752us       2.752us             1  
void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       2.624us         0.01%       2.624us       2.624us             1  
                                _gen_cumsum_pad0_kernel         0.00%       0.000us         0.00%       0.000us       0.000us       2.367us         0.01%       2.367us       2.367us             1  
                       _fwd_kernel_copy_kv_index_to_req         0.00%       0.000us         0.00%       0.000us       0.000us       1.729us         0.01%       1.729us       1.729us             1  
                                               aten::to         0.03%      14.241us         4.83%       1.991ms     331.892us       0.000us         0.00%       1.440us       0.240us             6  
                                         aten::_to_copy         0.05%      18.945us         4.79%       1.977ms     395.422us       0.000us         0.00%       1.440us       0.288us             5  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.440us         0.00%       1.440us       1.440us             1  
void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us       1.408us         0.00%       1.408us       1.408us             1  
                                              aten::sub         0.03%      12.639us         0.05%      22.326us      22.326us       1.248us         0.00%       1.248us       1.248us             1  
void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.248us         0.00%       1.248us       1.248us             1  
                                              aten::pad         0.02%       6.665us         0.35%     144.332us      36.083us       0.000us         0.00%       1.120us       0.280us             4  
                                  aten::constant_pad_nd         0.05%      18.611us         0.33%     137.667us      34.417us       0.000us         0.00%       1.120us       0.280us             4  
                                        aten::ones_like         0.00%       1.769us         0.03%      11.587us      11.587us       0.000us         0.00%       1.120us       1.120us             1  
                                             aten::view         0.03%      11.000us         0.03%      11.000us       1.571us       0.000us         0.00%       0.000us       0.000us             7  
                                    aten::empty_strided         0.06%      25.744us         0.06%      25.744us       4.291us       0.000us         0.00%       0.000us       0.000us             6  
                                Activity Buffer Request         4.48%       1.848ms         4.48%       1.848ms       1.848ms       0.000us         0.00%       0.000us       0.000us             1  
                                        cudaMemcpyAsync         0.30%     124.100us         0.30%     124.100us       5.641us       0.000us         0.00%       0.000us       0.000us            22  
                                            aten::empty         0.05%      22.486us         0.05%      22.486us       2.811us       0.000us         0.00%       0.000us       0.000us             8  
                                       cudaLaunchKernel         0.44%     181.674us         0.44%     181.674us      13.975us       0.000us         0.00%       0.000us       0.000us            13  
                                           aten::narrow         0.02%       8.274us         0.04%      18.122us       4.531us       0.000us         0.00%       0.000us       0.000us             4  
                                            aten::slice         0.06%      24.151us         0.07%      30.114us       2.510us       0.000us         0.00%       0.000us       0.000us            12  
                                       aten::as_strided         0.02%       9.025us         0.02%       9.025us       0.475us       0.000us         0.00%       0.000us       0.000us            19  
                                       cuLaunchKernelEx         0.04%      15.821us         0.04%      15.821us       7.910us       0.000us         0.00%       0.000us       0.000us             2  
                                       aten::empty_like         0.00%       1.322us         0.01%       4.192us       4.192us       0.000us         0.00%       0.000us       0.000us             1  
                                          aten::resize_         0.01%       4.976us         0.01%       4.976us       2.488us       0.000us         0.00%       0.000us       0.000us             2  
                                           aten::expand         0.01%       2.152us         0.01%       3.311us       1.655us       0.000us         0.00%       0.000us       0.000us             2  
                                          aten::reshape         0.01%       2.476us         0.01%       4.134us       2.067us       0.000us         0.00%       0.000us       0.000us             2  
                                  cudaStreamIsCapturing         0.00%       0.795us         0.00%       0.795us       0.795us       0.000us         0.00%       0.000us       0.000us             1  
                                        cudaGraphLaunch         8.77%       3.617ms         8.77%       3.617ms       3.617ms       0.000us         0.00%       0.000us       0.000us             1  
                                   cudaDriverGetVersion         0.00%       0.157us         0.00%       0.157us       0.157us       0.000us         0.00%       0.000us       0.000us             1  
                                  cudaDeviceSynchronize        85.14%      35.107ms        85.14%      35.107ms      35.107ms       0.000us         0.00%       0.000us       0.000us             1  
-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 41.233ms
Self CUDA time total: 34.168ms
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance

i: 4095, step cost time: 247.69210815429688 ms, throughput: 161.48879256989784 tokens/s
==================================================
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
Profile Prefill
Warning: please use at least NVCC 12.9 for the best DeepGEMM performance
